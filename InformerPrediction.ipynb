{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625ea9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5214e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"realtime_consumption_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e281cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption</th>\n",
       "      <th>Tarih</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31782.78</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30016.48</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28713.42</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27838.91</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27621.64</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27740.53</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28305.31</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29061.61</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31542.21</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34223.81</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   consumption       Tarih   hour\n",
       "0     31782.78  01.12.2018  00:00\n",
       "1     30016.48  01.12.2018  01:00\n",
       "2     28713.42  01.12.2018  02:00\n",
       "3     27838.91  01.12.2018  03:00\n",
       "4     27621.64  01.12.2018  04:00\n",
       "5     27740.53  01.12.2018  05:00\n",
       "6     28305.31  01.12.2018  06:00\n",
       "7     29061.61  01.12.2018  07:00\n",
       "8     31542.21  01.12.2018  08:00\n",
       "9     34223.81  01.12.2018  09:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc93904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52632 entries, 0 to 52631\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   consumption  52632 non-null  float64\n",
      " 1   Tarih        52632 non-null  object \n",
      " 2   hour         52632 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdbd627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri seti sütunları: Index(['Tarih', 'hour', 'total'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 17:05:43.953297: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-17 17:05:43.953321: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-12-17 17:05:43.953326: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-12-17 17:05:43.953388: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-17 17:05:43.953633: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 17:05:44.802468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 [==============================] - 13s 8ms/step - loss: 0.0058\n",
      "Epoch 2/10\n",
      "1151/1151 [==============================] - 10s 8ms/step - loss: 9.7595e-04\n",
      "Epoch 3/10\n",
      "1151/1151 [==============================] - 9s 8ms/step - loss: 6.9766e-04\n",
      "Epoch 4/10\n",
      "1151/1151 [==============================] - 10s 8ms/step - loss: 6.2552e-04\n",
      "Epoch 5/10\n",
      "1151/1151 [==============================] - 10s 8ms/step - loss: 5.8657e-04\n",
      "Epoch 6/10\n",
      "1151/1151 [==============================] - 10s 8ms/step - loss: 5.6710e-04\n",
      "Epoch 7/10\n",
      "1151/1151 [==============================] - 9s 8ms/step - loss: 5.3821e-04\n",
      "Epoch 8/10\n",
      "1151/1151 [==============================] - 9s 8ms/step - loss: 5.0144e-04\n",
      "Epoch 9/10\n",
      "1151/1151 [==============================] - 10s 8ms/step - loss: 4.5825e-04\n",
      "Epoch 10/10\n",
      "1151/1151 [==============================] - 9s 8ms/step - loss: 4.2744e-04\n",
      "Train Loss: 0.0005195781704969704, Test Loss: 0.0008430284215137362\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Tahmin edilen değer: [[35305.754]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "file_path = \"realtime_generation_data.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Veri seti sütunları:\", data.columns)\n",
    "\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(numeric_data)\n",
    "\n",
    "train_size = int(len(data_scaled) * 0.7)\n",
    "train_data = data_scaled[:train_size]\n",
    "test_data = data_scaled[train_size:]\n",
    "\n",
    "def create_sequences(dataset, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(dataset) - seq_length):\n",
    "        X.append(dataset[i:i+seq_length])\n",
    "        y.append(dataset[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 10  \n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(seq_length, numeric_data.shape[1])))\n",
    "model.add(Dense(numeric_data.shape[1]))  \n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "\n",
    "future_data = data_scaled[-seq_length:]  \n",
    "future_data = future_data.reshape((1, seq_length, numeric_data.shape[1]))\n",
    "predicted_data = model.predict(future_data)\n",
    "\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "print(f'Tahmin edilen değer: {predicted_data}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5530e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
